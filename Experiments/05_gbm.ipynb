{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# sampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# custom modules\n",
    "from utils import set_seed, get_clf_eval, make_submission, record_experimental_results\n",
    "import preprocessing as pp\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'seed': 33,\n",
    "    'num_ensemble': 30,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_hparams = {\n",
    "    'loss': 'log_loss', # The loss function to be optimized.\n",
    "    'learning_rate':0.1, # Learning rate shrinks the contribution of each tree by learning_rate. \n",
    "    'n_estimators': 100, # The number of boosting stages to perform.\n",
    "    'subsample': 1.0, # The fraction of samples to be used for fitting the individual base learners.\n",
    "    'criterion': 'friedman_mse', # The function to measure the quality of a split.\n",
    "    'min_samples_split': 2, # The minimum number of samples required to split an internal node:\n",
    "    'min_samples_leaf': 1, # The minimum number of samples required to be at a leaf node.\n",
    "    'max_depth': 3, # Maximum depth of the individual regression estimators.\n",
    "    'min_impurity_decrease': 0.0, # A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "    'init': None, # An estimator object that is used to compute the initial predictions.\n",
    "    # 'random_state': hparams['seed'], # Controls the random seed given to each Tree estimator at each boosting iteration.\n",
    "    'max_features': None, # The number of features to consider when looking for the best split:\n",
    "    'verbose': 0, # Enable verbose output.\n",
    "    'max_leaf_nodes': None, # Grow trees with max_leaf_nodes in best-first fashion.\n",
    "    'warm_start': False,\n",
    "    'validation_fraction': 0.1, # The proportion of training data to set aside as validation set for early stopping.\n",
    "    'n_iter_no_change': None, # n_iter_no_change is used to decide if early stopping will be used to terminate training when validation score is not improving.\n",
    "    'tol': 1e-4, # Tolerance for the early stopping.\n",
    "    'ccp_alpha': 0.0 # Complexity parameter used for Minimal Cost-Complexity Pruning.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 01: `GradientBoostingClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load & label encoding\n",
    "tr_data, tt_data = pp.load_data()\n",
    "x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr, seed=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "gbm = GradientBoostingClassifier(**gbm_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "gbm.fit(x_tr.fillna(0), y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check validation score\n",
    "y_val_pred = gbm.predict(x_val.fillna(0))\n",
    "get_clf_eval(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "x_tt = x_tt.drop(['is_converted', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = gbm.predict(x_tt.fillna(0))\n",
    "sum(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 02: `GradientBoostingClassifier()` ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_hparams02 = gbm_hparams.copy()\n",
    "gbm_hparams02['ccp_alpha'] = 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_hparams03 = gbm_hparams.copy()\n",
    "gbm_hparams03['max_depth'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_hparams04 = gbm_hparams03.copy()\n",
    "gbm_hparams04['n_estimators'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_hparams05 = gbm_hparams04.copy()\n",
    "gbm_hparams05['n_estimators'] = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load & drop dupliccates & normalize\n",
    "tr_data, tt_data = pp.load_data()\n",
    "tr_data, tt_data = pp.extract_country_name(tr_data, tt_data)\n",
    "\n",
    "# binning\n",
    "start, stop, step = 0, 47501, 500\n",
    "bins = np.arange(start, stop, step)\n",
    "labels = [i for i in range(len(bins) - 1)]\n",
    "\n",
    "tr_data['customer_idx'] = pd.Series(pd.cut(tr_data['customer_idx'], bins=bins, labels=labels), dtype='int64')\n",
    "tt_data['customer_idx'] = pd.Series(pd.cut(tt_data['customer_idx'], bins=bins, labels=labels), dtype='int64')\n",
    "\n",
    "# delete id_strategic_ver, it_strategic_ver\n",
    "tr_data, tt_data = pp.delete_features(tr_data, tt_data, features=['id_strategic_ver', 'it_strategic_ver', 'product_modelname', 'ver_cus', 'ver_pro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transformation\n",
    "cols = ['com_reg_ver_win_rate', 'historical_existing_cnt', 'lead_desc_length']\n",
    "for col in cols:\n",
    "    tr_data[col] = tr_data[col].apply(np.log1p)\n",
    "    tt_data[col] = tt_data[col].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regroup\n",
    "regroup_customer_type = [['End-Customer', 'End Customer', 'End-user', 'Commercial end-user'],\n",
    "                         ['Specifier / Influencer', 'Specifier/ Influencer'],\n",
    "                         ['Distributor', 'Dealer/Distributor'],\n",
    "                         ['Installer', 'Installer/Contractor'],\n",
    "                         ['Homeowner', 'Home Owner'],\n",
    "                         ['Others', 'other', 'Etc.', 'Other']]\n",
    "\n",
    "regroup_customer_job = [['engineering', 'engineering & technical', 'technical', 'engineer', 'chief engineer', 'engineering & technical executive'],\n",
    "                        ['others', 'other'],\n",
    "                        ['information technology', 'information_technology'],\n",
    "                        ['operations', 'operations manager'],\n",
    "                        ['business development', 'business_development'],\n",
    "                        ['art and design', 'arts and design', 'kreation_und_design', 'designer', 'arts_and_design'],\n",
    "                        ['program and project management', 'programm-_und_projektmanagement', 'program_and_project_management', 'projektmenedzsment\\tprogram and project management', 'manager', 'project manager', 'general manager', 'it manager', 'operations manager', 'sales manager'],\n",
    "                        ['media and communication', 'media_e_comunicazione'],\n",
    "                        ['healthcare services', 'healthcare_services'],\n",
    "                        ['community and social services', 'community_and_social_services'],\n",
    "                        ['research', 'research & development'],\n",
    "                        ['surgery professional', 'surgery professional\\u200b'],\n",
    "                        ['quality_assurance', 'quality_assurance'],\n",
    "                        ['director', 'it director', 'it', 'director of it'],\n",
    "                        ['ceo/founder', 'ceo'],\n",
    "                        ['architect', 'arquitecto/consultor'],\n",
    "                        ['finance', 'finanzen'],\n",
    "                        ['integrator', 'integrador'],\n",
    "                        ['coordinator', 'project coordinator'],\n",
    "                        ['administrative', 'administrative assistant']]\n",
    "\n",
    "regroup_inquiry_type = [['Quotation or purchase consultation', 'Quotation or Purchase Consultation', 'quotation_or_purchase_consultation', 'Quotation or Purchase consultation', 'quotation_', 'Request for quotation or purchase', 'Purchase or Quotation', 'Purchase'],\n",
    "                        ['Sales Inquiry', 'sales', 'Sales inquiry'],\n",
    "                        ['Usage or technical consultation', 'Technical Consultation', 'Usage or Technical Consultation', 'usage or technical consultation', 'usage_or_technical_consultation', 'technical_consultation', 'Technical Support', 'Request for technical consulting', 'technical'],\n",
    "                        ['Others', 'Other', 'ETC.', 'ETC.', 'Etc.', 'others', 'other', 'other_']]\n",
    "\n",
    "regroup_customer_position = [['others', 'other'],\n",
    "                             ['entry level', 'entrylevel'],\n",
    "                             ['c-level executive', 'c-levelexecutive'],\n",
    "                             ['vice president', 'vicepresident'],\n",
    "                             ['end-user', 'commercial end-user'],\n",
    "                             ['decision maker', 'decision-maker'],\n",
    "                             ['decision influencer', 'decision-influencer']]\n",
    "\n",
    "regroup_expected_timeline = [['less than 3 months', 'less_than_3_months'],\n",
    "                             ['3 months ~ 6 months', '3_months_~_6_months'],\n",
    "                             ['less than 6 months'],\n",
    "                             ['6 months ~ 9 months', '6_months_~_9_months'],\n",
    "                             ['more than a year'],\n",
    "                             ['being followed up', 'being followed up.'],\n",
    "                             ['no requirement', 'the client is not having any requirement hence closig in system. although the details of idb are mailed to client.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tt_data = pp.regroup(tr_data, tt_data, 'customer_type', regroup_customer_type, except_val='others', except_thr=5)\n",
    "tr_data, tt_data = pp.regroup(tr_data, tt_data, 'customer_job', regroup_customer_job, except_val='others', except_thr=5)\n",
    "tr_data, tt_data = pp.regroup(tr_data, tt_data, 'inquiry_type', regroup_inquiry_type, except_val='others', except_thr=2)\n",
    "tr_data, tt_data = pp.regroup(tr_data, tt_data, 'customer_position', regroup_customer_position, except_val='others', except_thr=6)\n",
    "tr_data, tt_data = pp.regroup(tr_data, tt_data, 'expected_timeline', regroup_expected_timeline, except_val='others', except_thr=1)\n",
    "tr_data, tt_data = pp.regroup(tr_data, tt_data, 'product_category', [[]], 'etc.', except_thr=5)\n",
    "tr_data, tt_data = pp.regroup(tr_data, tt_data, 'product_subcategory', [[]], 'others.', except_thr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "features = [\"business_subarea\", \"country\", \"business_area\", \"business_unit\", \"customer_type\",\n",
    "            \"enterprise\", \"customer_job\", \"inquiry_type\", \"product_category\", \n",
    "            \"product_subcategory\", \"customer_position\", \"response_corporate\",\"expected_timeline\"]\n",
    "\n",
    "tr_data, tt_data = pp.label_encoding(tr_data, tt_data, features=features)\n",
    "x_tt = tt_data.drop(['is_converted', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_precision, val_recall, val_f1 = [], [], [] # 모델별 validation score 저장\n",
    "test_results = np.zeros((hparams['num_ensemble'], 5271)) # 모델별 test 결과를 저장할 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hparams['num_ensemble']):\n",
    "    # 서로 다른 seed를 이용하여 undersampling 수행\n",
    "    rus = RandomUnderSampler(random_state=hparams['seed'] + i)\n",
    "    x_tr_res, y_tr_res = rus.fit_resample(tr_data.drop(['is_converted'], axis=1), tr_data['is_converted'])\n",
    "\n",
    "    # train / validation split\n",
    "    x_tr_res['is_converted'] = y_tr_res # concat\n",
    "    x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])\n",
    "\n",
    "    # define a model\n",
    "    model = GradientBoostingClassifier(**gbm_hparams05, \n",
    "                               random_state=hparams['seed'] + i)\n",
    "\n",
    "    # training\n",
    "    model.fit(x_tr.fillna(0), y_tr)\n",
    "    \n",
    "    ### print result of current model ###\n",
    "    print('-' * 20)\n",
    "    print(f'Model {i + 1} results')\n",
    "    print('-' * 20)\n",
    "\n",
    "    print(f'current seed: {hparams[\"seed\"] + i}')\n",
    "\n",
    "    # check validation score\n",
    "    y_val_pred = model.predict(x_val.fillna(0))\n",
    "    pr, re, f1 = get_clf_eval(y_val, y_val_pred, is_return=True)\n",
    "    \n",
    "    val_precision.append(pr)\n",
    "    val_recall.append(re)\n",
    "    val_f1.append(f1)\n",
    "\n",
    "    # test\n",
    "    y_test_pred = model.predict(x_tt.fillna(0))\n",
    "\n",
    "    # 예측 결과를 array에 누적\n",
    "    test_results[i, :] = y_test_pred\n",
    "\n",
    "    # number of positive predictions\n",
    "    print(sum(y_test_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"average validation precision score of {hparams['num_ensemble']} models: {sum(val_precision) / hparams['num_ensemble']:.6f}\")\n",
    "print(f\"average validation recall score of {hparams['num_ensemble']} models: {sum(val_recall) / hparams['num_ensemble']:.6f}\")\n",
    "print(f\"average validation f1 score of {hparams['num_ensemble']} models: {sum(val_f1) / hparams['num_ensemble']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting\n",
    "tmp = np.sum(test_results, axis=0, dtype=int)\n",
    "final_test_pred = np.array([1 if x >= int(hparams['num_ensemble'] / 2) + 1 else 0 for x in tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(final_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'hparams05_gbm_30_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='05_gbm',\n",
    "                y_pred=final_test_pred,\n",
    "                model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name=model_name,\n",
    "                            test_f1_score='0.755676',\n",
    "                            description='feature engineering + 30개 gbm ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgaimers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
