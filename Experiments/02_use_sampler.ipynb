{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# custom modules\n",
    "from utils import set_seed, get_clf_eval, make_submission, record_experimental_results\n",
    "import preprocessing as pp\n",
    "\n",
    "# preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'seed': 33,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(hparams['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 01: Positive sample oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load & label encoding\n",
    "tr_data, tt_data = pp.load_data()\n",
    "x_tr, x_tt = pp.label_encoding(tr_data, tt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling\n",
    "ros = RandomOverSampler(random_state=hparams['seed'])\n",
    "x_tr_res, y_tr_res = ros.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'[Before oversampling] size of training data : {len(x_tr)}')\n",
    "print(f'[After oversampling] size of training data : {len(x_tr_res)}')\n",
    "print('-' * 30)\n",
    "print(f'[After oversampling] distribution of training data : {Counter(y_tr_res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validation split\n",
    "x_tr_res['is_converted'] = y_tr_res # concat\n",
    "x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a model**\n",
    "- `DecisionTreeClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_tr.fillna(0), y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check validation score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(x_val.fillna(0))\n",
    "get_clf_eval(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tt = x_tt.drop(['is_converted', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_tt.fillna(0))\n",
    "sum(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='02_use_sampler',\n",
    "                f1_val=0.9902,\n",
    "                y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name='decision_tree_w_oversampling',\n",
    "                            test_f1_score='0.39189189189189194',\n",
    "                            description='모든 feature 사용/전처리 X/RandomOverSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 108898')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 02: Negative sample undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load & label encoding\n",
    "tr_data, tt_data = pp.load_data()\n",
    "x_tr, x_tt = pp.label_encoding(tr_data, tt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling\n",
    "rus = RandomUnderSampler(random_state=hparams['seed'])\n",
    "x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'[Before undersampling] size of training data : {len(x_tr)}')\n",
    "print(f'[After undersampling] size of training data : {len(x_tr_res)}')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print(f'[After undersampling] distribution of training data : {Counter(y_tr_res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validation split\n",
    "x_tr_res['is_converted'] = y_tr_res # concat\n",
    "x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'training data size : {len(x_tr)}, validation data size: {len(x_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a model**\n",
    "- `DecisionTreeClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_tr.fillna(0), y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check validation score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(x_val.fillna(0))\n",
    "get_clf_eval(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tt = x_tt.drop(['is_converted', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_tt.fillna(0))\n",
    "sum(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='02_use_sampler',\n",
    "                f1_val=0.8846,\n",
    "                y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name='decision_tree_w_undersampling',\n",
    "                            test_f1_score='0.5867215645908389',\n",
    "                            description='모든 feature 사용/전처리 X/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 03: Ensemble with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 30 # ensemble할 모델 개수\n",
    "test_results = np.zeros((num_models, len(x_tt))) # 모델별 test 결과를 저장할 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble loop\n",
    "for i in range(num_models):\n",
    "    # data load & label encoding\n",
    "    x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "\n",
    "    # 서로 다른 seed를 이용하여 undersampling 수행\n",
    "    rus = RandomUnderSampler(random_state=hparams['seed'] + i)\n",
    "    x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])\n",
    "\n",
    "    # train / validation split\n",
    "    x_tr_res['is_converted'] = y_tr_res # concat\n",
    "    x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])\n",
    "\n",
    "    # define a model\n",
    "    model = DecisionTreeClassifier(random_state=hparams['seed'] + i)\n",
    "\n",
    "    # training\n",
    "    model.fit(x_tr.fillna(0), y_tr)\n",
    "\n",
    "    # test\n",
    "    x_tt = x_tt.drop(['is_converted', 'id'], axis=1)\n",
    "    y_test_pred = model.predict(x_tt.fillna(0))\n",
    "\n",
    "    # 예측 결과를 array에 누적\n",
    "    test_results[i, :] = y_test_pred\n",
    "    \n",
    "\n",
    "    ### print result of current model ###\n",
    "    print('-' * 20)\n",
    "    print(f'Model {i + 1} results')\n",
    "    print('-' * 20)\n",
    "\n",
    "    print(f'current seed: {hparams[\"seed\"] + i}')\n",
    "\n",
    "    # check validation score\n",
    "    y_val_pred = model.predict(x_val.fillna(0))\n",
    "    get_clf_eval(y_val, y_val_pred)\n",
    "\n",
    "    # number of positive predictions\n",
    "    print(sum(y_test_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting -> 모델별 예측 결과 (1 또는 0) 를 모두 더한 뒤, 합이 int(num_models / 2) + 1 이상이면 1 (positive), 미만이면 0 (negative) 로 예측\n",
    "tmp = np.sum(test_results, axis=0, dtype=int)\n",
    "final_test_pred = np.array([1 if x >= int(num_models / 2) + 1 else 0 for x in tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(final_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='02_use_sampler',\n",
    "                f1_val=0.89097,\n",
    "                y_pred=final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name='ensemble_decisiontree_w_undersampling',\n",
    "                            test_f1_score='0.6696230598669624',\n",
    "                            description='30개 decision tree 사용/seed33~62/mean validation f1 score 0.89097/hard voting/결측치 0으로 처리')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 04: Decision tree with undersampling & feature preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing01: `customer_country.1` feature 삭제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load & label encoding & feature delete\n",
    "tr_data, tt_data = pp.load_data()\n",
    "x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "x_tr, x_tt = pp.delete_features(x_tr, x_tt, features=['customer_country.1'])\n",
    "\n",
    "print(len(tr_data.columns), len(x_tr.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing02: feature별 결측치 비율을 확인한 뒤, 비율이 높은 feature 삭제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tt_data = pp.load_data()\n",
    "tmp = pd.DataFrame(tr_data.isna().sum() / len(tr_data), columns=['nan_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 비율이 80% 이상인 feature 확인\n",
    "tmp[tmp['nan_ratio'] >= 0.8].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% 이상이 결측치인 feature + `customer_country.1` feature 삭제\n",
    "x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "x_tr, x_tt = pp.delete_features(x_tr, x_tt, features=['id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver',\n",
    "       'product_subcategory', 'product_modelname', 'business_subarea','customer_country.1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing03: `customer_country` feature normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tt_data = pp.load_data()\n",
    "\n",
    "# feature 정규화\n",
    "tr_data_cp, tt_data_cp = tr_data.copy(), tt_data.copy()\n",
    "tr_data_cp['customer_country'] = pp.normalize_country_name(tr_data['customer_country'])\n",
    "tt_data_cp['customer_country'] = pp.normalize_country_name(tt_data['customer_country'])\n",
    "\n",
    "# label encoding & customer_country.1 feature 삭제\n",
    "x_tr, x_tt = pp.label_encoding(tr_data_cp, tt_data_cp)\n",
    "x_tr, x_tt = pp.delete_features(x_tr, x_tt, features=['customer_country.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tr_data['customer_country'].unique()))\n",
    "print(len(x_tr['customer_country'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling\n",
    "rus = RandomUnderSampler(random_state=hparams['seed'])\n",
    "x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'[Before undersampling] size of training data : {len(x_tr)}')\n",
    "print(f'[After undersampling] size of training data : {len(x_tr_res)}')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print(f'[After undersampling] distribution of training data : {Counter(y_tr_res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validation split\n",
    "x_tr_res['is_converted'] = y_tr_res # concat\n",
    "x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'training data size : {len(x_tr)}, validation data size: {len(x_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a model**\n",
    "- `DecisionTreeClassifier()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_tr.fillna(0), y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check validation score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(x_val.fillna(0))\n",
    "get_clf_eval(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tt = x_tt.drop(['is_converted', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_tt.fillna(0))\n",
    "sum(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='02_use_sampler',\n",
    "                f1_val=0.8907,\n",
    "                y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name='decision_tree_w_undersampling_feature_normalization',\n",
    "                            test_f1_score='0.5541035023523261',\n",
    "                            description='\"customer_country\" 정규화/\"customer_country.1\" feature 삭제/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 05: Cost-Complexity Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ccp_alpha` 적정값 찾아보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load & label encoding\n",
    "tr_data, tt_data = pp.load_data()\n",
    "x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "\n",
    "# 서로 다른 seed를 이용하여 undersampling 수행\n",
    "rus = RandomUnderSampler(random_state=hparams['seed'])\n",
    "x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])\n",
    "\n",
    "# train / validation split\n",
    "x_tr_res['is_converted'] = y_tr_res # concat\n",
    "x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = model.cost_complexity_pruning_path(x_tr.fillna(0), y_tr)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=hparams['seed'], ccp_alpha=ccp_alpha)\n",
    "    clf.fit(x_tr.fillna(0), y_tr)\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "train_scores = [clf.score(x_tr.fillna(0), y_tr) for clf in clfs]\n",
    "test_scores = [clf.score(x_val.fillna(0), y_val) for clf in clfs]\n",
    "\n",
    "print(max(test_scores))\n",
    "print(f'best ccp_alpha: {ccp_alphas[test_scores.index(max(test_scores))]}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `0.00045` 값을 ccp_alpha 값으로 설정하여 실험해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 30 # ensemble할 모델 개수\n",
    "test_results = np.zeros((num_models, 5271)) # 모델별 test 결과를 저장할 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble loop\n",
    "for i in range(num_models):\n",
    "    # data load & label encoding\n",
    "    tr_data, tt_data = pp.load_data()\n",
    "    x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "\n",
    "    # 서로 다른 seed를 이용하여 undersampling 수행\n",
    "    rus = RandomUnderSampler(random_state=hparams['seed'] + i)\n",
    "    x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])\n",
    "\n",
    "    # train / validation split\n",
    "    x_tr_res['is_converted'] = y_tr_res # concat\n",
    "    x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])\n",
    "\n",
    "    # define a model\n",
    "    model = DecisionTreeClassifier(random_state=hparams['seed'] + i,\n",
    "                                   ccp_alpha=0.00045)\n",
    "\n",
    "    # training\n",
    "    model.fit(x_tr.fillna(0), y_tr)\n",
    "\n",
    "    # test\n",
    "    x_tt = x_tt.drop(['is_converted', 'id'], axis=1)\n",
    "    y_test_pred = model.predict(x_tt.fillna(0))\n",
    "\n",
    "    # 예측 결과를 array에 누적\n",
    "    test_results[i, :] = y_test_pred\n",
    "    \n",
    "\n",
    "    ### print result of current model ###\n",
    "    print('-' * 20)\n",
    "    print(f'Model {i + 1} results')\n",
    "    print('-' * 20)\n",
    "\n",
    "    print(f'current seed: {hparams[\"seed\"] + i}')\n",
    "\n",
    "    # check validation score\n",
    "    y_val_pred = model.predict(x_val.fillna(0))\n",
    "    get_clf_eval(y_val, y_val_pred)\n",
    "\n",
    "    # number of positive predictions\n",
    "    print(sum(y_test_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting -> 모델별 예측 결과 (1 또는 0) 를 모두 더한 뒤, 합이 int(num_models / 2) + 1 이상이면 1 (positive), 미만이면 0 (negative) 로 예측\n",
    "tmp = np.sum(test_results, axis=0, dtype=int)\n",
    "final_test_pred = np.array([1 if x >= int(num_models / 2) + 1 else 0 for x in tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(final_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='02_use_sampler',\n",
    "                f1_val=0.8960,\n",
    "                y_pred=final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name='ensemble_decisiontree_w_undersampling_and_ccp',\n",
    "                            test_f1_score='0.7121752419765665',\n",
    "                            description='30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/ccp_alpha 0.00045 사용/mean validation f1 score 0.8960/hard voting/결측치 0으로 처리/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 06: Cost-Complexity Pruning + `customer_country.1` feature 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ccp_alpha` 적정값 찾아보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load & label encoding & delete feature\n",
    "tr_data, tt_data = pp.load_data()\n",
    "x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "x_tr, x_tt = pp.delete_features(x_tr, x_tt, features=['customer_country.1'])\n",
    "\n",
    "# 서로 다른 seed를 이용하여 undersampling 수행\n",
    "rus = RandomUnderSampler(random_state=hparams['seed'])\n",
    "x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])\n",
    "\n",
    "# train / validation split\n",
    "x_tr_res['is_converted'] = y_tr_res # concat\n",
    "x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = model.cost_complexity_pruning_path(x_tr.fillna(0), y_tr)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=hparams['seed'], ccp_alpha=ccp_alpha)\n",
    "    clf.fit(x_tr.fillna(0), y_tr)\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "train_scores = [clf.score(x_tr.fillna(0), y_tr) for clf in clfs]\n",
    "test_scores = [clf.score(x_val.fillna(0), y_val) for clf in clfs]\n",
    "\n",
    "print(max(test_scores))\n",
    "print(f'best ccp_alpha: {ccp_alphas[test_scores.index(max(test_scores))]}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ccp_alpha` 값으로 0.0004 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 30 # ensemble할 모델 개수\n",
    "test_results = np.zeros((num_models, 5271)) # 모델별 test 결과를 저장할 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble loop\n",
    "for i in range(num_models):\n",
    "    # data load & label encoding & delete features\n",
    "    tr_data, tt_data = pp.load_data()\n",
    "    x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "    tr_data, tt_data = pp.delete_features(x_tr, x_tt, features=['customer_country.1'])\n",
    "\n",
    "    # 서로 다른 seed를 이용하여 undersampling 수행\n",
    "    rus = RandomUnderSampler(random_state=hparams['seed'] + i)\n",
    "    x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])\n",
    "\n",
    "    # train / validation split\n",
    "    x_tr_res['is_converted'] = y_tr_res # concat\n",
    "    x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])\n",
    "\n",
    "    # define a model\n",
    "    model = DecisionTreeClassifier(random_state=hparams['seed'] + i,\n",
    "                                   ccp_alpha=0.0004)\n",
    "\n",
    "    # training\n",
    "    model.fit(x_tr.fillna(0), y_tr)\n",
    "\n",
    "    # test\n",
    "    x_tt = x_tt.drop(['is_converted', 'id'], axis=1)\n",
    "    y_test_pred = model.predict(x_tt.fillna(0))\n",
    "\n",
    "    # 예측 결과를 array에 누적\n",
    "    test_results[i, :] = y_test_pred\n",
    "    \n",
    "\n",
    "    ### print result of current model ###\n",
    "    print('-' * 20)\n",
    "    print(f'Model {i + 1} results')\n",
    "    print('-' * 20)\n",
    "\n",
    "    print(f'current seed: {hparams[\"seed\"] + i}')\n",
    "\n",
    "    # check validation score\n",
    "    y_val_pred = model.predict(x_val.fillna(0))\n",
    "    get_clf_eval(y_val, y_val_pred)\n",
    "\n",
    "    # number of positive predictions\n",
    "    print(sum(y_test_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting -> 모델별 예측 결과 (1 또는 0) 를 모두 더한 뒤, 합이 int(num_models / 2) + 1 이상이면 1 (positive), 미만이면 0 (negative) 로 예측\n",
    "tmp = np.sum(test_results, axis=0, dtype=int)\n",
    "final_test_pred = np.array([1 if x >= int(num_models / 2) + 1 else 0 for x in tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(final_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='02_use_sampler',\n",
    "                f1_val=0.89571,\n",
    "                y_pred=final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name='ensemble_decisiontree_w_undersampling_ccp_delFeature',\n",
    "                            test_f1_score='0.7031170158405723',\n",
    "                            description='30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/ccp_alpha 0.0004 사용/\"customer_country.1\" feature 삭제/mean validation f1 score 0.89571/hard voting/결측치 0으로 처리/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 06+: CCP + `customer_country.1` feature 삭제 + 모델별 최적의 ccp_alpha 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 30 # ensemble할 모델 개수\n",
    "test_results = np.zeros((num_models, 5271)) # 모델별 test 결과를 저장할 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble loop\n",
    "for i in range(num_models):\n",
    "    # data load & label encoding & delete features\n",
    "    tr_data, tt_data = pp.load_data()\n",
    "    x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "    tr_data, tt_data = pp.delete_features(x_tr, x_tt, features=['customer_country.1'])\n",
    "\n",
    "    # 서로 다른 seed를 이용하여 undersampling 수행\n",
    "    rus = RandomUnderSampler(random_state=hparams['seed'] + i)\n",
    "    x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])\n",
    "\n",
    "    # train / validation split\n",
    "    x_tr_res['is_converted'] = y_tr_res # concat\n",
    "    x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])\n",
    "\n",
    "    ### find a best ccp_alpha value ###\n",
    "    model = DecisionTreeClassifier(random_state=hparams['seed'] + i)\n",
    "\n",
    "    path = model.cost_complexity_pruning_path(x_tr.fillna(0), y_tr)\n",
    "    ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "    clfs = []\n",
    "    for ccp_alpha in ccp_alphas:\n",
    "        clf = DecisionTreeClassifier(random_state=hparams['seed'], ccp_alpha=ccp_alpha)\n",
    "        clf.fit(x_tr.fillna(0), y_tr)\n",
    "        clfs.append(clf)\n",
    "\n",
    "    clfs = clfs[:-1]\n",
    "    ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "    train_scores = [clf.score(x_tr.fillna(0), y_tr) for clf in clfs]\n",
    "    test_scores = [clf.score(x_val.fillna(0), y_val) for clf in clfs]\n",
    "\n",
    "    best_ccp_alpha = ccp_alphas[test_scores.index(max(test_scores))]\n",
    "    print(f'best ccp_alpha: {best_ccp_alpha}')\n",
    "    ### find a best ccp_alpha value ###\n",
    "\n",
    "    # define a model\n",
    "    model = DecisionTreeClassifier(random_state=hparams['seed'] + i,\n",
    "                                   ccp_alpha=best_ccp_alpha)\n",
    "\n",
    "    # training\n",
    "    model.fit(x_tr.fillna(0), y_tr)\n",
    "\n",
    "    # test\n",
    "    x_tt = x_tt.drop(['is_converted', 'id'], axis=1)\n",
    "    y_test_pred = model.predict(x_tt.fillna(0))\n",
    "\n",
    "    # 예측 결과를 array에 누적\n",
    "    test_results[i, :] = y_test_pred\n",
    "    \n",
    "\n",
    "    ### print result of current model ###\n",
    "    print('-' * 20)\n",
    "    print(f'Model {i + 1} results')\n",
    "    print('-' * 20)\n",
    "\n",
    "    print(f'current seed: {hparams[\"seed\"] + i}')\n",
    "\n",
    "    # check validation score\n",
    "    y_val_pred = model.predict(x_val.fillna(0))\n",
    "    get_clf_eval(y_val, y_val_pred)\n",
    "\n",
    "    # number of positive predictions\n",
    "    print(sum(y_test_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting -> 모델별 예측 결과 (1 또는 0) 를 모두 더한 뒤, 합이 int(num_models / 2) + 1 이상이면 1 (positive), 미만이면 0 (negative) 로 예측\n",
    "tmp = np.sum(test_results, axis=0, dtype=int)\n",
    "final_test_pred = np.array([1 if x >= int(num_models / 2) + 1 else 0 for x in tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(final_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='02_use_sampler',\n",
    "                f1_val=0.900290,\n",
    "                y_pred=final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name='ensemble_decisiontree_w_undersampling_bestccpAlpha',\n",
    "                            test_f1_score='0.6965020576131687',\n",
    "                            description='30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/모델마다 best ccp alpha 찾아서 적용/mean validation f1 score 0.90029/hard voting/결측치 0으로 처리/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험 07: CCP + delete features that have a high nan ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ccp_alpha` 적정값 찾아보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load & label encoding & delete feature\n",
    "tr_data, tt_data = pp.load_data()\n",
    "x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "x_tr, x_tt = pp.delete_features(x_tr, x_tt, features=['customer_country.1', 'id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver',])\n",
    "\n",
    "# 서로 다른 seed를 이용하여 undersampling 수행\n",
    "rus = RandomUnderSampler(random_state=hparams['seed'])\n",
    "x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])\n",
    "\n",
    "# train / validation split\n",
    "x_tr_res['is_converted'] = y_tr_res # concat\n",
    "x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=hparams['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = model.cost_complexity_pruning_path(x_tr.fillna(0), y_tr)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=hparams['seed'], ccp_alpha=ccp_alpha)\n",
    "    clf.fit(x_tr.fillna(0), y_tr)\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "train_scores = [clf.score(x_tr.fillna(0), y_tr) for clf in clfs]\n",
    "test_scores = [clf.score(x_val.fillna(0), y_val) for clf in clfs]\n",
    "\n",
    "print(max(test_scores))\n",
    "print(f'best ccp_alpha: {ccp_alphas[test_scores.index(max(test_scores))]}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ccp_alpha` 값으로 0.00046 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 30 # ensemble할 모델 개수\n",
    "test_results = np.zeros((num_models, 5271)) # 모델별 test 결과를 저장할 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble loop\n",
    "for i in range(num_models):\n",
    "    # data load & label encoding & delete features\n",
    "    tr_data, tt_data = pp.load_data()\n",
    "    x_tr, x_tt = pp.label_encoding(tr_data, tt_data)\n",
    "    tr_data, tt_data = pp.delete_features(x_tr, x_tt, features=['customer_country.1', 'id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver'])\n",
    "\n",
    "    # 서로 다른 seed를 이용하여 undersampling 수행\n",
    "    rus = RandomUnderSampler(random_state=hparams['seed'] + i)\n",
    "    x_tr_res, y_tr_res = rus.fit_resample(x_tr.drop(['is_converted'], axis=1), x_tr['is_converted'])\n",
    "\n",
    "    # train / validation split\n",
    "    x_tr_res['is_converted'] = y_tr_res # concat\n",
    "    x_tr, y_tr, x_val, y_val = pp.split_train_and_validation(x_tr_res, seed=hparams['seed'])\n",
    "\n",
    "    # define a model\n",
    "    model = DecisionTreeClassifier(random_state=hparams['seed'] + i,\n",
    "                                   ccp_alpha=0.00046)\n",
    "\n",
    "    # training\n",
    "    model.fit(x_tr.fillna(0), y_tr)\n",
    "\n",
    "    # test\n",
    "    x_tt = x_tt.drop(['is_converted', 'id'], axis=1)\n",
    "    y_test_pred = model.predict(x_tt.fillna(0))\n",
    "\n",
    "    # 예측 결과를 array에 누적\n",
    "    test_results[i, :] = y_test_pred\n",
    "    \n",
    "\n",
    "    ### print result of current model ###\n",
    "    print('-' * 20)\n",
    "    print(f'Model {i + 1} results')\n",
    "    print('-' * 20)\n",
    "\n",
    "    print(f'current seed: {hparams[\"seed\"] + i}')\n",
    "\n",
    "    # check validation score\n",
    "    y_val_pred = model.predict(x_val.fillna(0))\n",
    "    get_clf_eval(y_val, y_val_pred)\n",
    "\n",
    "    # number of positive predictions\n",
    "    print(sum(y_test_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting -> 모델별 예측 결과 (1 또는 0) 를 모두 더한 뒤, 합이 5 이상이면 1 (positive), 5 미만이면 0 (negative) 로 예측\n",
    "tmp = np.sum(test_results, axis=0, dtype=int)\n",
    "final_test_pred = np.array([1 if x >= 5 else 0 for x in tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(final_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(dir_name='02_use_sampler',\n",
    "                f1_val=0.89734,\n",
    "                y_pred=final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_experimental_results(model_name='ensemble_decisiontree_w_undersampling_ccp_delFeatures',\n",
    "                            test_f1_score='0.693579766536965',\n",
    "                            description='10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.00046 사용/\"customer_country.1, id_strategic_ver, it_strategic_ver, idit_strategic_ver\" feature 삭제/mean validation f1 score 0.89734/hard voting/결측치 0으로 처리/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgaimers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
