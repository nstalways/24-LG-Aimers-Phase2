{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampler를 이용한 실험 결과 (전체)\n",
    "- Test f1 score 기준 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2024-02-13/23:54:57</td>\n",
       "      <td>randomForest_params05</td>\n",
       "      <td>0.717894</td>\n",
       "      <td>randomForest_params02 실험에서 ccp_alpha 값을 0.00005 만큼 감소</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024-02-21/22:52:54</td>\n",
       "      <td>randomForest_params05_logTransform</td>\n",
       "      <td>0.717894</td>\n",
       "      <td>randomForest_params05 실험에서 lead_desc_length feature에 log transformation 적용</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2024-02-13/23:43:00</td>\n",
       "      <td>randomForest_params02</td>\n",
       "      <td>0.717277</td>\n",
       "      <td>randomForest_params01 실험에서 n_estimators를 100으로 증가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024-02-13/23:52:17</td>\n",
       "      <td>randomForest_params04</td>\n",
       "      <td>0.710445</td>\n",
       "      <td>randomForest_params02 실험에서 ccp_alpha 값을 0.00005 만큼 높임</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2024-02-13/23:27:34</td>\n",
       "      <td>randomForest_params01</td>\n",
       "      <td>0.704509</td>\n",
       "      <td>모든 feature 사용/전처리 X/RandomForestClassifier 사용/결측치는 0으로 채움/Seed 33/ensemble_decisiontree_w_undersampling_and_ccp 실험과 유사하게 param setting/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024-02-21/14:45:37</td>\n",
       "      <td>randomForest_params05_delFeatures</td>\n",
       "      <td>0.672525</td>\n",
       "      <td>randomForest_params05 세팅 + is_converted가 True인 데이터와 False인 데이터 간에 분포 차이가 많이 나지 않는 features를 모두 삭제하고, 7개만 사용</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024-02-21/14:52:03</td>\n",
       "      <td>randomForest_params06</td>\n",
       "      <td>0.669417</td>\n",
       "      <td>randomForest_params05_delFeatrues 세팅에서 ccp_alpha 값을 0.001 감소</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024-02-18/22:04:47</td>\n",
       "      <td>randomForest_params05_cityAndCountry</td>\n",
       "      <td>0.647125</td>\n",
       "      <td>randomForest_params05 실험 + customer_country feature를 city와 country로 분리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-02-13/23:47:35</td>\n",
       "      <td>randomForest_params03</td>\n",
       "      <td>0.628806</td>\n",
       "      <td>randomForest_params02 실험에서 max_features를 \"sqrt\"로 변경</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date                            model_name  test_f1_score  \\\n",
       "29  2024-02-13/23:54:57                 randomForest_params05       0.717894   \n",
       "35  2024-02-21/22:52:54    randomForest_params05_logTransform       0.717894   \n",
       "26  2024-02-13/23:43:00                 randomForest_params02       0.717277   \n",
       "28  2024-02-13/23:52:17                 randomForest_params04       0.710445   \n",
       "25  2024-02-13/23:27:34                 randomForest_params01       0.704509   \n",
       "33  2024-02-21/14:45:37     randomForest_params05_delFeatures       0.672525   \n",
       "34  2024-02-21/14:52:03                 randomForest_params06       0.669417   \n",
       "32  2024-02-18/22:04:47  randomForest_params05_cityAndCountry       0.647125   \n",
       "27  2024-02-13/23:47:35                 randomForest_params03       0.628806   \n",
       "\n",
       "                                                                                                                                description  \n",
       "29                                                                                    randomForest_params02 실험에서 ccp_alpha 값을 0.00005 만큼 감소  \n",
       "35                                                               randomForest_params05 실험에서 lead_desc_length feature에 log transformation 적용  \n",
       "26                                                                                        randomForest_params01 실험에서 n_estimators를 100으로 증가  \n",
       "28                                                                                    randomForest_params02 실험에서 ccp_alpha 값을 0.00005 만큼 높임  \n",
       "25  모든 feature 사용/전처리 X/RandomForestClassifier 사용/결측치는 0으로 채움/Seed 33/ensemble_decisiontree_w_undersampling_and_ccp 실험과 유사하게 param setting/  \n",
       "33                              randomForest_params05 세팅 + is_converted가 True인 데이터와 False인 데이터 간에 분포 차이가 많이 나지 않는 features를 모두 삭제하고, 7개만 사용  \n",
       "34                                                                             randomForest_params05_delFeatrues 세팅에서 ccp_alpha 값을 0.001 감소  \n",
       "32                                                                   randomForest_params05 실험 + customer_country feature를 city와 country로 분리  \n",
       "27                                                                                      randomForest_params02 실험에서 max_features를 \"sqrt\"로 변경  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv(\"../experimental_records.csv\")\n",
    "df = df[df['model_name'].apply(lambda x: True if x.find('randomForest') + 1 else False)]\n",
    "df.sort_values(by='test_f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style='color:orange'>[0.717894, Best]</span> 실험 01: RandomForestClassifier**\n",
    "\n",
    "**Motivation**\n",
    "- Undersampling, cost-complexity pruning을 각각의 decision tree에 적용한 뒤 ensemble했을 때 test f1 score가 크게 향상된다는 사실을 이전 실험을 통해 파악하였음.\n",
    "- 여러 개의 decision tree를 ensemble하는 것은 random forest 전략과 동일한데, 직접 구현한 것과 `sklearn.ensemble.RandomForestClassifier()` 를 이용하는 것 사이의 성능 차이를 확인해보고 싶었고, 본 실험을 진행하게 되었음.\n",
    "- `sklearn.ensemble.RandomForestClassifier()`의 경우 다양한 hyperparameters를 지원하기 때문에, 조합에 따라 다양한 모델을 만들 수 있다는 장점이 존재함\n",
    "\n",
    "**Basic rfc params**\n",
    "```python\n",
    "rfc_params_01 = {\n",
    "    'n_estimators': 30, # 사용할 decision tree의 개수\n",
    "    'criterion': 'gini', # statement의 분류 성능을 평가할 기준\n",
    "    'max_depth': None, # tree의 최대 깊이\n",
    "    'min_samples_split': 2, # internal node를 나누기 위해 필요한 최소 샘플 개수 (이 값 이하면 split X)\n",
    "    'min_samples_leaf': 1, # min_samples_leaf 이상의 samples을 가져야만 leaf node로 간주됨 (?)\n",
    "    'min_weight_fraction_leaf': 0.0, # ?\n",
    "    'max_features': None, # best split을 찾기 위해 고려할 features의 개수\n",
    "    'max_leaf_nodes': None, # ?\n",
    "    'min_impurity_decrease': 0.0, # 특정 node를 split할 때, impurity가 이 값 이상 감소해야만 split을 수행\n",
    "    'bootstrap': True, # sampling을 통해 만든 subset 간 데이터 중복을 허용하는지 여부. (False이면 모든 tree가 동일한 dataset 이용)\n",
    "    'oob_score': True, # out-of-bag sample을 이용해 일반화 성능을 측정할 때 사용 (bootstrap==True일 때만 사용가능)\n",
    "    'n_jobs': None, # 작업을 병렬적으로 수행하고 싶을 때 사용 (-1이면 모든 CPU 코어를 사용)\n",
    "    'random_state': hparams['seed'], # 모델링 과정에 필요한 randomness를 부여할 때 사용할 값\n",
    "    'verbose': 1, # fitting 과정에 대한 정보를 어느 정도로 출력할 지 결정\n",
    "    'warm_start': False, # 이전에 만들었던 forest가 존재한다면, 해당 정보를 참고하여 새로운 forest를 build (재현가능성을 위해 False로 고정)\n",
    "    'class_weight': \"balanced_subsample\", # class 비율을 고려하여 sampling할 때 사용\n",
    "    'ccp_alpha': 0.00045, # cost-complexity pruning에 사용할 alpha 값\n",
    "    'max_samples': None, # sampling 할 데이터의 총 개수\n",
    "    # 'monotonic_cst': None, # available at >= 1.4\n",
    "}   \n",
    "```\n",
    "\n",
    "**Test f1 score**\n",
    "- `RandomForestClassifier()` 의 다양한 hyperparameters 에 따른 실험 결과 table\n",
    "- Previous best test f1 score: 0.712175\n",
    "\n",
    "    |rfc_params|test f1 score| description |\n",
    "    |:-:|:-:|:-:|\n",
    "    | 01 | 0.704509 (-0.007666) | Basic rfc params 참고 |\n",
    "    | 02 | 0.717277 (+0.005102) | params01 에서 n_estimators를 100으로 증가 |\n",
    "    | 03 | 0.628806 (-0.083369) | params02 실험에서 max_features를 \"sqrt\"로 변경 |\n",
    "    | 04 | 0.710445 (-0.00173)  | params02 실험에서 ccp_alpha 값을 0.00005 만큼 높임 |\n",
    "    | 05 | 0.717894 (+0.005719) | params02 실험에서 ccp_alpha 값을 0.00005 만큼 감소 |\n",
    "\n",
    "**Analysis**\n",
    "- `sklearn.ensemble.RandomForestClassifier()` 또한 `sklearn.tree.DecisionTreeClassifier()` 를 기반으로 구현된 것이다 보니, `02_use_sampler.ipynb` 에서 실험했던 결과와 유의미한 차이를 보이지 않았음.\n",
    "- ensemble에 사용하는 tree의 개수를 100개까지 높이고, ccp_alpha 값을 조금 줄여주었을 때 test f1 score가 아주 소폭 향상되었음.\n",
    "\n",
    "**Future works**\n",
    "- gradient boosting models\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[0.717894] 실험 02: Skewed data transformation**\n",
    "\n",
    "**Motivation**\n",
    "- Feature distribution이 한 쪽으로 치우쳐져 있는 skewed feature에 대해 log transformation을 가해 모델이 극단적인 분포를 학습하지 않도록 하고자 하였음.\n",
    "- 여러 skewed feature 중 target 예측에 어느 정도 영향을 주는 feature인 `lead_desc_length` feature에만 `np.log1p()` transformation을 적용하였음.\n",
    "\n",
    "**Basic rfc params**\n",
    "```python\n",
    "rfc_params_05 = {\n",
    "    'n_estimators': 100, \n",
    "    'criterion': 'gini', \n",
    "    'max_depth': None, \n",
    "    'min_samples_split': 2, \n",
    "    'min_samples_leaf': 1, \n",
    "    'min_weight_fraction_leaf': 0.0, \n",
    "    'max_features': None,\n",
    "    'max_leaf_nodes': None, \n",
    "    'min_impurity_decrease': 0.0, \n",
    "    'bootstrap': True, \n",
    "    'oob_score': True, \n",
    "    'n_jobs': None, \n",
    "    'random_state': hparams['seed'], \n",
    "    'verbose': 1, \n",
    "    'warm_start': False, \n",
    "    'class_weight': \"balanced_subsample\", \n",
    "    'ccp_alpha': 0.0004,\n",
    "    'max_samples': None, \n",
    "}   \n",
    "```\n",
    "\n",
    "**Test f1 score**\n",
    "- Previous best test f1 score: 0.717894\n",
    "\n",
    "    |rfc_params|test f1 score| description |\n",
    "    |:-:|:-:|:-:|\n",
    "    | 05 | 0.717894 (+0.00) | params05 세팅 + `lead_desc_length`에 log transformation 적용 |\n",
    "\n",
    "**Analysis**\n",
    "- 변환 전/후를 비교했을 때 skew 정도가 완화되긴 하였음.\n",
    "- 다만 target 예측에 있어 `customer_idx` feature가 미치는 영향이 너무 컸던 탓인지, transformation에 따른 성능 향상은 전혀 없었음.\n",
    "- 학습에 활용가능한 28개의 feature 중 특정 feature에 대한 의존도가 너무 높은 것 같아서,, 유의미한 새로운 feature를 만들던가 모델 클래스를 바꾸어보던가 해야할 것 같음.\n",
    "\n",
    "**Future works**\n",
    "- Feature engineering 등\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리\n",
    "\n",
    "`+`\n",
    "- Increase number of estimators\n",
    "- Decrease ccp_alpha value\n",
    "---\n",
    "`-`\n",
    "- Use small number of features (e.g., sqrt, log_2)\n",
    "- Increase ccp_alpha value\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future works (`02_use_sampler.ipynb`와 동일)\n",
    "\n",
    "- 모델 (e.g., svm, gbm, AdaBoost, lightGBM, XGBoost, CatBoost) 변경\n",
    "- 새로운 기법 탐색 (e.g., Logistic Regression, Out-Of-Distribution Detection)\n",
    "- 결측값 처리\n",
    "- feature engineering\n",
    "- data augmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgaimers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
