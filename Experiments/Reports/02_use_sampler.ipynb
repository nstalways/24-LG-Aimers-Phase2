{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampler를 이용한 실험 결과 (전체)\n",
    "- Test f1 score 기준 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024-02-12/00:52:24</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_and_ccp</td>\n",
       "      <td>0.712175</td>\n",
       "      <td>30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/ccp_alpha 0.00045 사용/mean validation f1 score 0.8960/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2024-02-12/01:14:02</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_ccp_delFeature</td>\n",
       "      <td>0.703117</td>\n",
       "      <td>30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/ccp_alpha 0.0004 사용/\"customer_country.1\" feature 삭제/mean validation f1 score 0.89571/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2024-02-12/11:45:10</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_bestccpAlpha</td>\n",
       "      <td>0.696502</td>\n",
       "      <td>30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/모델마다 best ccp alpha 찾아서 적용/mean validation f1 score 0.90029/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2024-02-12/01:55:22</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_bestccpAlpha_delFeature</td>\n",
       "      <td>0.696502</td>\n",
       "      <td>30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/모델마다 best ccp alpha 찾아서 적용/\"customer_country.1\" feature 삭제/mean validation f1 score 0.90029/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-02-08/16:18:57</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_ccp_delFeature</td>\n",
       "      <td>0.695737</td>\n",
       "      <td>10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.0004 사용/\"customer_country.1\" feature 삭제/mean validation f1 score 0.89659/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-02-11/16:29:16</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_ccp_delFeatures</td>\n",
       "      <td>0.693580</td>\n",
       "      <td>10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.00046 사용/\"customer_country.1, id_strategic_ver, it_strategic_ver, idit_strategic_ver\" feature 삭제/mean validation f1 score 0.89734/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-02-07/18:27:07</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_and_ccp</td>\n",
       "      <td>0.691334</td>\n",
       "      <td>10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.00045 사용/mean validation f1 score 0.89745/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-02-11/16:22:37</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_ccp_delFeatures</td>\n",
       "      <td>0.691334</td>\n",
       "      <td>10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.00045 사용/\"customer_country.1, id_strategic_ver, it_strategic_ver, idit_strategic_ver\" feature 삭제/mean validation f1 score 0.89745/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024-02-12/00:02:37</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling</td>\n",
       "      <td>0.669623</td>\n",
       "      <td>30개 decision tree 사용/seed33~62/mean validation f1 score 0.89097/hard voting/결측치 0으로 처리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-02-11/18:20:36</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling</td>\n",
       "      <td>0.665550</td>\n",
       "      <td>20개 decision tree 사용/seed33~52/mean validation f1 score 0.89073/hard voting/결측치 0으로 처리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-02-06/00:00:20</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling</td>\n",
       "      <td>0.652855</td>\n",
       "      <td>10개 decision tree 사용/seed33~42/mean validation f1 score 0.89055/hard voting/결측치 0으로 처리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-02-07/18:22:53</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_and_seed</td>\n",
       "      <td>0.651697</td>\n",
       "      <td>10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/mean validation f1 score 0.88982/hard voting/결측치 0으로 처리/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-02-06/11:45:07</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling</td>\n",
       "      <td>0.649734</td>\n",
       "      <td>20개 decision tree 사용/seed33~52/mean validation f1 score 0.89215/hard voting/결측치 0으로 처리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-02-06/15:20:02</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling_and_delete_feature</td>\n",
       "      <td>0.638188</td>\n",
       "      <td>10개 decision tree 사용/\"customer_country.1\" feature 삭제/seed33~52/mean validation f1 score 0.89007/hard voting/결측치 0으로 처리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-02-11/18:13:58</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling</td>\n",
       "      <td>0.623391</td>\n",
       "      <td>5개 decision tree 사용/seed33~37/mean validation f1 score 0.89006/hard voting/결측치 0으로 처리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-02-06/14:51:02</td>\n",
       "      <td>decision_tree_w_undersampling_delete_feature</td>\n",
       "      <td>0.610570</td>\n",
       "      <td>\"customer_country.1\" feature 삭제/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-02-11/18:17:33</td>\n",
       "      <td>ensemble_decisiontree_w_undersampling</td>\n",
       "      <td>0.592551</td>\n",
       "      <td>10개 decision tree 사용/seed33~42/mean validation f1 score 0.88982/hard voting/결측치 0으로 처리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-02-05/22:53:27</td>\n",
       "      <td>decision_tree_w_undersampling</td>\n",
       "      <td>0.586722</td>\n",
       "      <td>모든 feature 사용/전처리 X/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-02-06/15:02:31</td>\n",
       "      <td>decision_tree_w_undersampling_delete_features</td>\n",
       "      <td>0.581432</td>\n",
       "      <td>결측치 비율이 80% 이상인 feature 및 \"customer_country.1\" feature 삭제/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-02-06/15:12:31</td>\n",
       "      <td>decision_tree_w_undersampling_feature_normalization</td>\n",
       "      <td>0.554104</td>\n",
       "      <td>\"customer_country\" 정규화/\"customer_country.1\" feature 삭제/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-05/17:56:50</td>\n",
       "      <td>decision_tree_w_oversampling</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>모든 feature 사용/전처리 X/RandomOverSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 108898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  \\\n",
       "21  2024-02-12/00:52:24   \n",
       "22  2024-02-12/01:14:02   \n",
       "24  2024-02-12/11:45:10   \n",
       "23  2024-02-12/01:55:22   \n",
       "14  2024-02-08/16:18:57   \n",
       "16  2024-02-11/16:29:16   \n",
       "13  2024-02-07/18:27:07   \n",
       "15  2024-02-11/16:22:37   \n",
       "20  2024-02-12/00:02:37   \n",
       "19  2024-02-11/18:20:36   \n",
       "6   2024-02-06/00:00:20   \n",
       "12  2024-02-07/18:22:53   \n",
       "7   2024-02-06/11:45:07   \n",
       "11  2024-02-06/15:20:02   \n",
       "17  2024-02-11/18:13:58   \n",
       "8   2024-02-06/14:51:02   \n",
       "18  2024-02-11/18:17:33   \n",
       "5   2024-02-05/22:53:27   \n",
       "9   2024-02-06/15:02:31   \n",
       "10  2024-02-06/15:12:31   \n",
       "4   2024-02-05/17:56:50   \n",
       "\n",
       "                                                       model_name  \\\n",
       "21                  ensemble_decisiontree_w_undersampling_and_ccp   \n",
       "22           ensemble_decisiontree_w_undersampling_ccp_delFeature   \n",
       "24             ensemble_decisiontree_w_undersampling_bestccpAlpha   \n",
       "23  ensemble_decisiontree_w_undersampling_bestccpAlpha_delFeature   \n",
       "14           ensemble_decisiontree_w_undersampling_ccp_delFeature   \n",
       "16          ensemble_decisiontree_w_undersampling_ccp_delFeatures   \n",
       "13                  ensemble_decisiontree_w_undersampling_and_ccp   \n",
       "15          ensemble_decisiontree_w_undersampling_ccp_delFeatures   \n",
       "20                          ensemble_decisiontree_w_undersampling   \n",
       "19                          ensemble_decisiontree_w_undersampling   \n",
       "6                           ensemble_decisiontree_w_undersampling   \n",
       "12                 ensemble_decisiontree_w_undersampling_and_seed   \n",
       "7                           ensemble_decisiontree_w_undersampling   \n",
       "11       ensemble_decisiontree_w_undersampling_and_delete_feature   \n",
       "17                          ensemble_decisiontree_w_undersampling   \n",
       "8                    decision_tree_w_undersampling_delete_feature   \n",
       "18                          ensemble_decisiontree_w_undersampling   \n",
       "5                                   decision_tree_w_undersampling   \n",
       "9                   decision_tree_w_undersampling_delete_features   \n",
       "10            decision_tree_w_undersampling_feature_normalization   \n",
       "4                                    decision_tree_w_oversampling   \n",
       "\n",
       "    test_f1_score  \\\n",
       "21       0.712175   \n",
       "22       0.703117   \n",
       "24       0.696502   \n",
       "23       0.696502   \n",
       "14       0.695737   \n",
       "16       0.693580   \n",
       "13       0.691334   \n",
       "15       0.691334   \n",
       "20       0.669623   \n",
       "19       0.665550   \n",
       "6        0.652855   \n",
       "12       0.651697   \n",
       "7        0.649734   \n",
       "11       0.638188   \n",
       "17       0.623391   \n",
       "8        0.610570   \n",
       "18       0.592551   \n",
       "5        0.586722   \n",
       "9        0.581432   \n",
       "10       0.554104   \n",
       "4        0.391892   \n",
       "\n",
       "                                                                                                                                                                                                                      description  \n",
       "21                                                                                           30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/ccp_alpha 0.00045 사용/mean validation f1 score 0.8960/hard voting/결측치 0으로 처리/  \n",
       "22                                                           30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/ccp_alpha 0.0004 사용/\"customer_country.1\" feature 삭제/mean validation f1 score 0.89571/hard voting/결측치 0으로 처리/  \n",
       "24                                                                                    30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/모델마다 best ccp alpha 찾아서 적용/mean validation f1 score 0.90029/hard voting/결측치 0으로 처리/  \n",
       "23                                                    30개 decision tree 사용, decision tree마다 seed 세팅/seed33~62/모델마다 best ccp alpha 찾아서 적용/\"customer_country.1\" feature 삭제/mean validation f1 score 0.90029/hard voting/결측치 0으로 처리/  \n",
       "14                                                           10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.0004 사용/\"customer_country.1\" feature 삭제/mean validation f1 score 0.89659/hard voting/결측치 0으로 처리/  \n",
       "16  10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.00046 사용/\"customer_country.1, id_strategic_ver, it_strategic_ver, idit_strategic_ver\" feature 삭제/mean validation f1 score 0.89734/hard voting/결측치 0으로 처리/  \n",
       "13                                                                                          10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.00045 사용/mean validation f1 score 0.89745/hard voting/결측치 0으로 처리/  \n",
       "15  10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/ccp_alpha 0.00045 사용/\"customer_country.1, id_strategic_ver, it_strategic_ver, idit_strategic_ver\" feature 삭제/mean validation f1 score 0.89745/hard voting/결측치 0으로 처리/  \n",
       "20                                                                                                                                         30개 decision tree 사용/seed33~62/mean validation f1 score 0.89097/hard voting/결측치 0으로 처리  \n",
       "19                                                                                                                                         20개 decision tree 사용/seed33~52/mean validation f1 score 0.89073/hard voting/결측치 0으로 처리  \n",
       "6                                                                                                                                          10개 decision tree 사용/seed33~42/mean validation f1 score 0.89055/hard voting/결측치 0으로 처리  \n",
       "12                                                                                                               10개 decision tree 사용, decision tree마다 seed 세팅/seed33~52/mean validation f1 score 0.88982/hard voting/결측치 0으로 처리/  \n",
       "7                                                                                                                                          20개 decision tree 사용/seed33~52/mean validation f1 score 0.89215/hard voting/결측치 0으로 처리  \n",
       "11                                                                                                         10개 decision tree 사용/\"customer_country.1\" feature 삭제/seed33~52/mean validation f1 score 0.89007/hard voting/결측치 0으로 처리  \n",
       "17                                                                                                                                          5개 decision tree 사용/seed33~37/mean validation f1 score 0.89006/hard voting/결측치 0으로 처리  \n",
       "8                                                                                                                              \"customer_country.1\" feature 삭제/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760  \n",
       "18                                                                                                                                         10개 decision tree 사용/seed33~42/mean validation f1 score 0.88982/hard voting/결측치 0으로 처리  \n",
       "5                                                                                                                                          모든 feature 사용/전처리 X/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760  \n",
       "9                                                                                                    결측치 비율이 80% 이상인 feature 및 \"customer_country.1\" feature 삭제/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760  \n",
       "10                                                                                                      \"customer_country\" 정규화/\"customer_country.1\" feature 삭제/RandomUnderSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 7760  \n",
       "4                                                                                                                                         모든 feature 사용/전처리 X/RandomOverSampler 적용/결측치는 0으로 채움/Seed 33/training data size: 108898  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv(\"../experimental_records.csv\")\n",
    "df = df[df['model_name'].apply(lambda x: True if x.find('sampling') + 1 else False)]\n",
    "df.sort_values(by='test_f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style='color:blue'>[0.391892]</span> 실험 01: Positive sample oversampling**\n",
    "\n",
    "**Motivation**\n",
    "- Data imbalance 문제를 positive sample에 대해 oversampling 함으로써 해결해보고자 시도\n",
    "\n",
    "**Test f1 score**\n",
    "- 0.391892 (-0.083564) | Best: 0.475456\n",
    "\n",
    "**Analysis**\n",
    "- Negative sample이 positive sample보다 10배 이상 많은 상황에서 positive sample을 oversampling했기 때문에 중복되는 positive sample이 너무 많아졌음.\n",
    "- 중복되는 positive sample들을 올바르게 분류하도록 학습하다보니 분류 기준이 이상해지게 되었고 (overfitting), 그로 인해 test f1 score가 크게 하락한 것으로 분석하였음.\n",
    "\n",
    "**Future works**\n",
    "- Undersampling\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style='color:red'>[0.586722]</span> 실험 02: Negative sample undersampling**\n",
    "\n",
    "**Motivation**\n",
    "- 데이터 수가 훨씬 많은 negative sample을 undersampling하여 positive sample과 비율을 맞춰준다면, training data에 overfitting 되는 현상을 완화할 수 있을 것으로 기대\n",
    "\n",
    "**Test f1 score**\n",
    "- 0.586722 (+0.111266) | Best: 0.475456\n",
    "\n",
    "**Analysis**\n",
    "- Decision tree의 특성 상, 특정 class의 samples이 많은 경우 해당 samples를 잘 분류하도록 만들어지기 때문에 bias가 생길 수 있음.\n",
    "- Sampling을 통해서 적어도 negative / positive class 간의 imbalance는 해소해주었기 때문에, test f1 score가 큰 폭으로 향상될 수 있었다고 분석하였음.\n",
    "\n",
    "**Future works**\n",
    "- 버려지는 negative samples를 활용할 수 있는 방법을 찾아볼 것\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style='color:red'>[0.669623]</span> 실험 03: Ensemble with undersampling**\n",
    "\n",
    "**Motivation**\n",
    "- Positive samples의 수에 맞게 negative samples를 undersampling하게 되면서 버려지는 negative samples이 너무 많았음.\n",
    "- 서로 다른 seed 값을 사용해 sampling 함으로써 서로 다른 data subset을 만들고, 각각의 data subset을 학습한 모델들을 ensemble 한다면, 특정 subset 에만 overfitting 되는 문제를 완화할 수 있을 것으로 기대.\n",
    "\n",
    "**Test f1 score**\n",
    "- Previous best test f1 score: 0.586722\n",
    "- 사용한 voting : hard voting (과반수를 초과하는 모델이 1이라고 예측 시 1, 이하는 0)\n",
    "- Ensemble한 모델의 개수에 따른 test f1 score table\n",
    "\n",
    "|num_models|test f1 score|\n",
    "|:-:|:-:|\n",
    "| 5 | 0.623391 (+0.036669) |\n",
    "| 10 | 0.592551 (+0.005829) |\n",
    "| 20 | 0.665550 (+0.078828) |\n",
    "| 30 | 0.669623 (+0.082901) |\n",
    "\n",
    "**Analysis**\n",
    "- Negative samples은 subset마다 다르고 positive samples은 모든 subset이 동일함.\n",
    "- Subset마다 다른 negative samples로 인해 각각의 classification tree는 약간씩 다른 분류 기준을 가지게 되고, 예측 결과에 있어 다양성을 가질 수 있을 것이라 생각함.\n",
    "- 모든 classification tree가 같은 positive samples을 학습했기 때문에, 이와 비슷한 test data가 입력되는 경우 아주 높은 확률로 positive samples로 예측할 것.\n",
    "- 반면에 모든 classification tree가 약간씩 다른 negative samples을 학습했기 때문에, 임의의 test data가 입력되는 경우 voting을 통해서 negative samples을 판단하게 될 것.\n",
    "- 본 실험에서 test f1 score가 크게 높아질 수 있었던 주된 이유는 negative samples의 분류 능력이 높아졌기 때문으로 분석함.\n",
    "---\n",
    "- 모델 개수에 따른 성능 차이를 비교분석했을 때, 30 개의 모델을 ensemble 했을 때가 가장 높은 성능을 기록\n",
    "- 10개일 때 성능이 떨어진 것은 seed 의 영향으로 보임\n",
    "\n",
    "**Future works**\n",
    "- positive samples을 증강할 수 있는 방법\n",
    "- feature preprocessing\n",
    "- pruning\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style='color:red'>[0.610570]</span> 실험 04: Decision tree with undersampling & feature preprocessing**\n",
    "\n",
    "**Motivation**\n",
    "- Sampling 없이, feature preprocessing 후 classification tree를 모델링했을 때 모두 성능이 하락하였으나, 성능 하락의 원인이 불분명하다고 판단하여 재실험을 진행하고자 하였음.\n",
    "- 총 3가지의 시나리오를 수행\n",
    "\n",
    "**Test f1 score**\n",
    "- 비교군: 실험 B (0.586722)\n",
    "\n",
    "|scenario|test f1 score|\n",
    "|:-:|:-:|\n",
    "|`customer_country.1` feature 삭제|0.610570 (+0.023848)|\n",
    "|`customer_country.1` feature 삭제 + 결측치 비율 80% 이상인 features 삭제|0.581432 (-0.00529)|\n",
    "|`customer_country.1` feature 삭제 + `customer_country` feature 정규화|0.554104 (-0.032618)|\n",
    "\n",
    "**Analysis**\n",
    "- scenario 01: `customer_country` feature 삭제\n",
    "    - `customer_country` 와 `customer_country.1` feature 간의 correlation이 1에 가까울 정도로 유사하다는 점을 EDA를 통해 확인하였고, 둘 중 하나를 삭제하여 불필요한 정보를 학습하지 못하도록 방지하고자 하였음.\n",
    "    - 실험 B 대비 큰 폭으로 향상\n",
    "- scenario 02: `customer_country.1` feature 삭제 + 결측치 비율 80% 이상인 features 삭제\n",
    "    - 현재 결측치는 모두 0으로 채우고 있기 때문에, 결측치 비율이 80% 이상이라면 학습이 무의미하다고 생각하여 삭제하고자 하였음.\n",
    "    - 삭제한 features : `['id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver',\n",
    "       'product_subcategory', 'product_modelname', 'business_subarea','customer_country.1']`\n",
    "    - 한 번에 너무 많은 features를 삭제하면서 성능 하락의 원인이 불분명 -> 추가 실험을 진행해야할 것으로 보임\n",
    "    - 확실한 것은 결측치 비율이 높다고 해서 feature를 삭제하는 것은 오히려 성능 하락의 원인이 된다는 것\n",
    "- scenario 03: `customer_country.1` feature 삭제 + `customer_country` feature 정규화\n",
    "    - `customer_country` feature는 고객이 기입한 국적 정보인데, 나라 뿐만 아니라 도시 정보도 함께 기입되면서 종류의 수가 너무 많았음. 세부 정보들이 불필요한 정보들이라고 판단하여 도시 정보만 남기는 방식으로 정규화를 시도, 성능을 확인하였으나 오히려 큰 폭으로 성능이 떨어짐.\n",
    "    - 상세한 국적 정보가 target 예측에 오히려 도움이 되었다는 것을 확인.\n",
    "\n",
    "**Future works**\n",
    "- 결측치 비율이 높은 features에 대한 ablation study\n",
    "- 결측값을 어떤 값으로 채울 것인가?\n",
    "- `customer_country` feature를 오히려 세분화하여 feature의 양을 늘린다면?\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style='color:orange'>[0.712175, best]</span> 실험 05: Cost-Complexity Pruning**\n",
    "\n",
    "**Motivation**\n",
    "- 실험 03을 통해 서로 다른 subset을 학습한 모델을 ensemble 했을 때 generalization 성능이 향상된 것을 확인하였음.\n",
    "- 다만 각각의 모델이 자기가 학습한 subset에 대해 overfitting 되는 문제는 여전히 남아있었음.\n",
    "- Cost-complexity pruning을 통해 overfitting 문제를 완화한 뒤 ensemble 한다면 generalization 성능을 더 높일 수 있을 것이라 판단하여 실험을 진행\n",
    "- 총 30개의 모델을 ensemble 하였음\n",
    "\n",
    "**Test f1 score**\n",
    "- `customer_country.1` feature를 삭제한 상태에서, 두 가지 시나리오를 실험.\n",
    "- Prev best test f1 score: 0.669623\n",
    "\n",
    "|scenario|mean validation f1 score|test f1 score|\n",
    "|:-:|:-:|:-:|\n",
    "|임의의 subset 하나에 대한 best ccp_alpha (0.00045) 를 모든 모델에 적용|0.8960|0.712175 (+0.042552)|\n",
    "|subset마다 best ccp_alpha를 구해 학습|0.90029|0.696502 (+0.026879)|\n",
    "\n",
    "**Analysis**\n",
    "- CCP를 통해 분류 결과가 극도로 세분화되는 문제를 완화 (training data만 잘 분류할 수 있도록 모델링되는 문제를 완화)\n",
    "- Overfitting 문제가 완화된 모델들을 ensemble 하면서 generalization 성능이 극대화된 것으로 분석\n",
    "- 조금 의아했던 것은 subset별 best ccp_alpha 값을 구해서 적용했을 때 성능이 조금 더 높아질 것이라고 예상했던 것과 반대의 결과가 나왔다는 것\n",
    "- 러프하게 ccp_alpha 값을 적용한 것과 subset별 best ccp_alpha 값을 적용한 것을 비교했을 때, 전자에 비해 후자가 subset에 좀 더 fitting되면서 general한 예측을 하지 못하게 된 것이라고 분석하였음.\n",
    "\n",
    "**Future works**\n",
    "- feature preprocessing과 결합\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style='color:blue'>[0.703117]</span> 실험 06: Cost-Complexity Pruning + `customer_country.1` feature 삭제**\n",
    "\n",
    "**Motivation**\n",
    "- 실험 04-01 을 통해 `customer_country.1` feature를 삭제했을 때 test f1 score 가 높아지는 것을 확인\n",
    "- 따라서 이전의 best 모델이었던 실험 05 세팅에 04-01 세팅을 합친다면 test f1 score 를 더 높일 수 있을 것이라 판단하고 실험을 진행\n",
    "- 총 30개의 모델을 ensemble 하였음.\n",
    "\n",
    "**Test f1 score**\n",
    "- `customer_country.1` feature를 삭제한 상태에서, 두 가지 시나리오를 실험.\n",
    "\n",
    "|scenario|mean validation f1 score|test f1 score|\n",
    "|:-:|:-:|:-:|\n",
    "|subset 하나에 대한 best ccp_alpha를 모든 모델에 적용|0.89571|0.703117 (-0.009058)|\n",
    "|subset마다 best ccp_alpha를 구해 학습|0.90029|0.696502 (-0.015673)|\n",
    "\n",
    "**Analysis**\n",
    "- Feature 간에 correlation이 1에 가깝다는 것은 분포가 거의 동일하다는 얘기임.\n",
    "- 이 말은 target을 예측할 때 둘 중 하나는 없어도 무방하다는 의미.\n",
    "- 허나 `customer_country.1` feature를 삭제했을 때 성능이 하락하였음.\n",
    "- 여러 subset을 만들고 이를 학습하는 과정에서, 특정 subset의 경우 `customer_country.1` feature의 중요도가 높았을 수도 있음.\n",
    "- `customer_country.1` feature의 중요도가 높았던 subset 들에서 feature를 제거하게 되면서, 해당 subset을 학습한 모델의 분류 성능은 떨어지게 되고, 이러한 모델들이 모이게 되면서 최종적으로 성능이 떨어진 게 아닌가 싶음.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리\n",
    "\n",
    "`+`\n",
    "- Negative samples undersampling\n",
    "- Ensemble\n",
    "- Cost-Complexity Pruning\n",
    "---\n",
    "`-`\n",
    "- Positive samples oversampling\n",
    "- Feature preprocessing\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future works\n",
    "\n",
    "- 모델 (e.g., svm, gbm, AdaBoost, lightGBM, XGBoost, CatBoost) 변경\n",
    "- 새로운 기법 탐색 (e.g., Logistic Regression, Out-Of-Distribution Detection)\n",
    "- 결측값 처리\n",
    "- feature engineering\n",
    "- data augmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgaimers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
